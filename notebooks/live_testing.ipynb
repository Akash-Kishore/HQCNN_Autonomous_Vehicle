{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7950b392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "from IPython.display import display, Image, clear_output\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION\n",
    "# ==========================================\n",
    "# ‚ö†Ô∏è UPDATE YOUR IP HERE (Check the app on your phone!)\n",
    "# Ensure '/video' is at the end of the URL\n",
    "PHONE_IP = \"http://192.168.29.229:8080/video\" \n",
    "\n",
    "# File to load (ensure this matches your uploaded file name)\n",
    "WEIGHTS_FILE = \"hqcnn_unfrozen_best.pth\"\n",
    "\n",
    "# ==========================================\n",
    "# 2. MODEL SETUP & ARCHITECTURE\n",
    "# ==========================================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"üöÄ Device: {device}\")\n",
    "\n",
    "# Define GTSRB Classes (0-42)\n",
    "CLASSES = {\n",
    "    0: 'Speed 20', 1: 'Speed 30', 2: 'Speed 50', 3: 'Speed 60', 4: 'Speed 70', \n",
    "    5: 'Speed 80', 6: 'End 80', 7: 'Speed 100', 8: 'Speed 120', 9: 'No Passing', \n",
    "    10: 'No Truck Passing', 11: 'Priority Crossroad', 12: 'Priority Road', \n",
    "    13: 'Yield', 14: 'STOP', 15: 'No Vehicles', 16: 'No Trucks', 17: 'No Entry', \n",
    "    18: 'Caution', 19: 'Curve Left', 20: 'Curve Right', 21: 'Double Curve', \n",
    "    22: 'Bumpy Road', 23: 'Slippery', 24: 'Narrow Road', 25: 'Road Work', \n",
    "    26: 'Signals', 27: 'Pedestrians', 28: 'Children', 29: 'Bicycles', \n",
    "    30: 'Ice/Snow', 31: 'Wild Animals', 32: 'End Speed Limit', 33: 'Turn Right', \n",
    "    34: 'Turn Left', 35: 'Ahead Only', 36: 'Straight/Right', 37: 'Straight/Left', \n",
    "    38: 'Keep Right', 39: 'Keep Left', 40: 'Roundabout', 41: 'End No Pass', \n",
    "    42: 'End No Truck Pass'\n",
    "}\n",
    "\n",
    "# Define Architecture (Must match training exactly)\n",
    "class QuantumLayer(nn.Module):\n",
    "    def __init__(self, n_qubits=8): \n",
    "        super(QuantumLayer, self).__init__()\n",
    "        self.n_qubits = n_qubits\n",
    "        self.theta = nn.Parameter(torch.randn(n_qubits) * 0.1) \n",
    "    def forward(self, x):\n",
    "        return torch.cos(x) * torch.sin(self.theta) + torch.sin(x) * torch.cos(self.theta)\n",
    "\n",
    "class HQCNN(nn.Module):\n",
    "    def __init__(self, n_classes=43):\n",
    "        super(HQCNN, self).__init__()\n",
    "        self.base_model = models.resnet18(weights=None)\n",
    "        self.base_model.fc = nn.Identity() \n",
    "        self.bridge = nn.Linear(512, 8) \n",
    "        self.quantum_layer = QuantumLayer(n_qubits=8)\n",
    "        self.classifier = nn.Linear(8, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)     \n",
    "        x = self.bridge(x)        \n",
    "        feat = self.quantum_layer(x)\n",
    "        out = self.classifier(feat)     \n",
    "        return out\n",
    "\n",
    "# robust path finding logic\n",
    "if os.path.exists(WEIGHTS_FILE):\n",
    "    path = WEIGHTS_FILE\n",
    "elif os.path.exists(os.path.join('notebooks', WEIGHTS_FILE)):\n",
    "    path = os.path.join('notebooks', WEIGHTS_FILE)\n",
    "else:\n",
    "    # Try absolute path based on your WSL info\n",
    "    path = f'/home/akash_kishore/HQCNN_Project/notebooks/{WEIGHTS_FILE}'\n",
    "\n",
    "print(f\"üìÇ Loading weights from: {path}\")\n",
    "\n",
    "# Load the model\n",
    "try:\n",
    "    model = HQCNN(n_classes=43).to(device)\n",
    "    if torch.cuda.is_available():\n",
    "        ckpt = torch.load(path, weights_only=False)\n",
    "    else:\n",
    "        ckpt = torch.load(path, map_location='cpu', weights_only=False)\n",
    "    model.load_state_dict(ckpt)\n",
    "    model.eval()\n",
    "    print(\"‚úÖ Model Loaded Successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading model: {e}\")\n",
    "    # We don't raise here to allow debugging, but logic below might fail if model isn't loaded\n",
    "\n",
    "# ==========================================\n",
    "# 3. BROWSER VIDEO LOOP (INLINE DISPLAY)\n",
    "# ==========================================\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(f\"üì° Connecting to Phone at {PHONE_IP}...\")\n",
    "cap = cv2.VideoCapture(PHONE_IP)\n",
    "cap.set(cv2.CAP_PROP_BUFFERSIZE, 1) # Low latency setting\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"‚ùå Connection Failed! Check IP address or restart app.\")\n",
    "else:\n",
    "    print(\"‚úÖ Video Stream Started! (Press the Square 'Stop' button in Jupyter toolbar to end)\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"‚ö†Ô∏è Stream Ended / Frame Drop\")\n",
    "            break\n",
    "            \n",
    "        # ROI Logic (Green Box)\n",
    "        h, w, _ = frame.shape\n",
    "        box = 300\n",
    "        x1, y1 = (w - box)//2, (h - box)//2\n",
    "        x2, y2 = x1 + box, y1 + box\n",
    "        \n",
    "        roi = frame[y1:y2, x1:x2]\n",
    "        \n",
    "        if roi.size > 0:\n",
    "            # Inference\n",
    "            roi_pil = PILImage.fromarray(cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))\n",
    "            input_tensor = preprocess(roi_pil).unsqueeze(0).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                out = model(input_tensor)\n",
    "                probs = torch.nn.functional.softmax(out, dim=1)\n",
    "                score, idx = torch.max(probs, 1)\n",
    "                raw_label = CLASSES[idx.item()]\n",
    "                conf = score.item() * 100\n",
    "            \n",
    "            # --- CONFIDENCE THRESHOLD LOGIC ---\n",
    "            if conf > 90.0:\n",
    "                label_text = f\"{raw_label}: {conf:.0f}%\"\n",
    "                color = (0, 255, 0) # Green\n",
    "            else:\n",
    "                label_text = \"Scanning...\"\n",
    "                color = (128, 128, 128) # Grey\n",
    "            \n",
    "            # Draw UI\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 3)\n",
    "            # Label Background\n",
    "            cv2.rectangle(frame, (x1, y1-40), (x1+300, y1), color, -1)\n",
    "            # Text\n",
    "            cv2.putText(frame, label_text, (x1+10, y1-10), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "            \n",
    "        # Display in Notebook (Inline)\n",
    "        _, buffer = cv2.imencode('.jpg', frame)\n",
    "        clear_output(wait=True)\n",
    "        display(Image(data=buffer.tobytes()))\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(\"üõë Stream Stopped by User\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Runtime Error: {e}\")\n",
    "finally:\n",
    "    cap.release()\n",
    "    print(\"üîå Camera Released\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8645abf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hqcnn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
